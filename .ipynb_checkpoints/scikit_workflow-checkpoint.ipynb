{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b8827a",
   "metadata": {},
   "source": [
    "# Titanic - Machine Learning From Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a6c0e7",
   "metadata": {},
   "source": [
    "## Sckit Learn Workflow Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c577eb93",
   "metadata": {},
   "source": [
    "The goal of this notebook is to analyze the Titanic passenge dataset, provided in the Titanic - Machine Learning From Disaster Kaggle competition. This data will then be used to predict the survival of a set of passengers based on similar features.\n",
    "\n",
    "This version of the project will focus more on deploying a scikit workflow, and pipelining the process in a scalable manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94fc8135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "\n",
    "sns.set_theme(style='darkgrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33721a2",
   "metadata": {},
   "source": [
    "## Importing and Spliting Into Train/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b973de27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 0 rows missing target variable\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Read data\n",
    "X = pd.read_csv('data/train.csv', index_col='PassengerId')\n",
    "X_test_full = pd.read_csv('data/test.csv', index_col='PassengerId')\n",
    "\n",
    "# Remove rows with missing target, print num rows dropped\n",
    "rows_full = len(X.index)\n",
    "X.dropna(axis=0, subset=['Survived'], inplace=True)\n",
    "print(f'Dropped {rows_full - len(X.index)} rows missing target variable')\n",
    "\n",
    "# Separate target from predictors\n",
    "y = X.Survived\n",
    "X.drop(['Survived'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Select numeric and categoric columns\n",
    "numeric_cols = [cname for cname in X.columns \n",
    "                if X[cname].dtype in ['int64', 'float64']]\n",
    "categoric_cols = [cname for cname in X.columns\n",
    "                  if X[cname].dtype == 'object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c965f4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Pclass                                               Name  \\\n",
       "PassengerId                                                              \n",
       "1                 3                            Braund, Mr. Owen Harris   \n",
       "2                 1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "3                 3                             Heikkinen, Miss. Laina   \n",
       "4                 1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "5                 3                           Allen, Mr. William Henry   \n",
       "\n",
       "                Sex   Age  SibSp  Parch            Ticket     Fare Cabin  \\\n",
       "PassengerId                                                                \n",
       "1              male  22.0      1      0         A/5 21171   7.2500   NaN   \n",
       "2            female  38.0      1      0          PC 17599  71.2833   C85   \n",
       "3            female  26.0      0      0  STON/O2. 3101282   7.9250   NaN   \n",
       "4            female  35.0      1      0            113803  53.1000  C123   \n",
       "5              male  35.0      0      0            373450   8.0500   NaN   \n",
       "\n",
       "            Embarked  \n",
       "PassengerId           \n",
       "1                  S  \n",
       "2                  C  \n",
       "3                  S  \n",
       "4                  S  \n",
       "5                  S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8319b403",
   "metadata": {},
   "source": [
    "## Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d5ced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking entire training dataset for nulls\n",
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f398c605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age          86\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          1\n",
       "Cabin       327\n",
       "Embarked      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking competition test dataset for nulls\n",
    "X_test_full.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e8eb96",
   "metadata": {},
   "source": [
    "The test data has 1 null for 'Fare', though the training data does not. For this reason, I will build the pipeline with an imputer for 'Fare'. The baseline model will include no feature engineering. 'Age' and 'Embarked' will be imputed, and 'Cabin' will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb374aa",
   "metadata": {},
   "source": [
    "### Selecting Features for Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52000a",
   "metadata": {},
   "source": [
    "The basline model will only include low cardinality features. That is categorical features with less than 15 unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3fc09a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns with low cardinality\n",
    "categoric_cols = [cname for cname in X.columns if\n",
    "                    X[cname].nunique() < 10 and \n",
    "                    X[cname].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74ced01",
   "metadata": {},
   "source": [
    "For the purpose of this model, the feature 'Pclass' will be considered a categoric feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a3cb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_cols.append('Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4686f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sex', 'Embarked', 'Pclass']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categoric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3818374e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numeric_cols.remove('Pclass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "468bb754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'SibSp', 'Parch', 'Fare']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ab7c5697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unused features\n",
    "X = X[categoric_cols + numeric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0f18fc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and validation sets\n",
    "X_train, X_valid, y_train, y_valid, = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001c5837",
   "metadata": {},
   "source": [
    "## Creating Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b812e1d9",
   "metadata": {},
   "source": [
    "### Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf9f116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# impute 'Age'\n",
    "# impute 'Fare'\n",
    "# impute 'Embarked'\n",
    "\n",
    "# Create numerical column transformers\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Create categorical column transformers\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle Preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categoric_cols)\n",
    "    ])\n",
    "\n",
    "# Scale all features\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ce7a99",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6aeef32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Select Model\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('scaler', scaler),\n",
    "                             ('model', model)])\n",
    "\n",
    "# Fit model to training set\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Create predictions on validation set\n",
    "preds = my_pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faf35d8",
   "metadata": {},
   "source": [
    "## Model Evalutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3245dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88       110\n",
      "           1       0.84      0.74      0.78        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.84      0.82      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98eba6b9",
   "metadata": {},
   "source": [
    "## Model Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8fc6e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 14, 'n_estimators': 212}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Select range of parameters for search\n",
    "param_distributions = {'n_estimators': randint(1, 500),\n",
    "                       'max_depth': randint(5, 100)}\n",
    "\n",
    "# Optimize parameters for random forest classifier\n",
    "search = RandomizedSearchCV(estimator=RandomForestClassifier(random_state=0),\n",
    "                            n_iter=5,\n",
    "                            param_distributions=param_distributions,\n",
    "                            random_state=0)\n",
    "\n",
    "# Change estimator to the optimized model\n",
    "my_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                             ('scaler', scaler),\n",
    "                             ('model', search)])\n",
    "\n",
    "# Fit model to training set\n",
    "my_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Print optimized parameters\n",
    "print(search.best_params_)\n",
    "\n",
    "# Create predictions on validation set\n",
    "preds = my_pipeline.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cb62e2",
   "metadata": {},
   "source": [
    "### Evaluate Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0eab28ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.92      0.88       110\n",
      "           1       0.85      0.72      0.78        69\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.84      0.82      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380123df",
   "metadata": {},
   "source": [
    "## Create Submission Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1ec52d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test = my_pipeline.predict(X_test_full)\n",
    "output = pd.DataFrame({'PassengerId': X_test_full.index,\n",
    "                       'Survived': preds_test})\n",
    "#output.to_csv('data/submission_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b6a768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
